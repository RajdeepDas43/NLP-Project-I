{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "336ff0ec",
   "metadata": {},
   "source": [
    " # PROJECT TITLE: CHATBOT IMPLEMENTATION IN CUSTOMER SERVICE INDUSTRY "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4f799d",
   "metadata": {},
   "source": [
    "###  TEAMMATES  \n",
    "    Likhita Chandana Adabala  \n",
    "    Naveen Kumar Desireddygari \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "918bb263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch \n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9de1d05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Conversation_Chatbot.xlsx', usecols=['question', 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d81f6df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi, how are you doing?</td>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "      <td>i've been great. what about you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i've been great. what about you?</td>\n",
       "      <td>i've been good. i'm in school right now.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              question  \\\n",
       "0               hi, how are you doing?   \n",
       "1        i'm fine. how about yourself?   \n",
       "2  i'm pretty good. thanks for asking.   \n",
       "3    no problem. so how have you been?   \n",
       "4     i've been great. what about you?   \n",
       "\n",
       "                                     answer  \n",
       "0             i'm fine. how about yourself?  \n",
       "1       i'm pretty good. thanks for asking.  \n",
       "2         no problem. so how have you been?  \n",
       "3          i've been great. what about you?  \n",
       "4  i've been good. i'm in school right now.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c0a35ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "\n",
    "def preprocessing(sentence):    \n",
    "    return re.sub('[,.]', '', sentence.lower())\n",
    "df['question'] = df['question'].apply(preprocessing)\n",
    "df['answer'] = df['answer'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ed54950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi how are you doing?</td>\n",
       "      <td>i'm fine how about yourself?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i'm fine how about yourself?</td>\n",
       "      <td>i'm pretty good thanks for asking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm pretty good thanks for asking</td>\n",
       "      <td>no problem so how have you been?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no problem so how have you been?</td>\n",
       "      <td>i've been great what about you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i've been great what about you?</td>\n",
       "      <td>i've been good i'm in school right now</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            question                                  answer\n",
       "0              hi how are you doing?            i'm fine how about yourself?\n",
       "1       i'm fine how about yourself?       i'm pretty good thanks for asking\n",
       "2  i'm pretty good thanks for asking        no problem so how have you been?\n",
       "3   no problem so how have you been?         i've been great what about you?\n",
       "4    i've been great what about you?  i've been good i'm in school right now"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e568777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tokenGenerator:\n",
    "    def __init__(self, conversation):\n",
    "        self.conversation = conversation\n",
    "        self.tokens_list = []\n",
    "        self.word_freq = {}\n",
    "        self.unique_words = set()\n",
    "        self.W2I = {}\n",
    "        self.I2W = {}\n",
    "        \n",
    "    def counter(self):\n",
    "        self.tokens_list = [word for sentence in self.conversation for word in sentence.split()]\n",
    "        self.word_freq = Counter(self.tokens_list)\n",
    "        self.unique_words = set(self.tokens_list)\n",
    "        self.W2I = {word: i for i, word in enumerate(self.unique_words)}\n",
    "        self.I2W = {i: word for word, i in self.W2I.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c09d589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quest_tokenizer = tokenGenerator(df['question'])\n",
    "quest_tokenizer.counter()\n",
    "ans_tokenizer = tokenGenerator(df['answer'])\n",
    "ans_tokenizer.counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6669c165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in questions: 1193\n",
      "Number of unique words in questions: 356\n",
      "Most common words in questions: [('the', 54), ('yale', 40), ('in', 35), ('you', 34), ('is', 30), ('a', 28), ('for', 19), ('what', 19), ('to', 19), ('it', 19)]\n",
      "Index of 'the' in questions: 29\n",
      "Word at index 100 in questions: attend?\n",
      "Number of words in answers: 1021\n",
      "Number of unique words in answers: 343\n",
      "Most common words in answers: [('the', 39), ('you', 33), ('in', 26), ('yale', 25), ('is', 24), ('a', 23), ('it', 22), ('and', 22), ('yes', 17), ('program', 17)]\n",
      "Index of 'the' in answers: 26\n",
      "Word at index 100 in answers: at\n"
     ]
    }
   ],
   "source": [
    "# Printing out results\n",
    "print(f\"Number of words in questions: {len(quest_tokenizer.tokens_list)}\")\n",
    "print(f\"Number of unique words in questions: {len(quest_tokenizer.unique_words)}\")\n",
    "print(f\"Most common words in questions: {quest_tokenizer.word_freq.most_common(10)}\")\n",
    "print(f\"Index of 'the' in questions: {quest_tokenizer.W2I.get('the')}\")\n",
    "print(f\"Word at index 100 in questions: {quest_tokenizer.I2W.get(100)}\")\n",
    "\n",
    "print(f\"Number of words in answers: {len(ans_tokenizer.tokens_list)}\")\n",
    "print(f\"Number of unique words in answers: {len(ans_tokenizer.unique_words)}\")\n",
    "print(f\"Most common words in answers: {ans_tokenizer.word_freq.most_common(10)}\")\n",
    "print(f\"Index of 'the' in answers: {ans_tokenizer.W2I.get('the')}\")\n",
    "print(f\"Word at index 100 in answers: {ans_tokenizer.I2W.get(100)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f33274ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "330cf20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OwnDataset(Dataset):\n",
    "    def __init__(self, conversation, quest_tokenizer, ans_tokenizer):\n",
    "        self.conversation = conversation\n",
    "        self.end_token = 1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.conversation)\n",
    "     \n",
    "    def __getitem__(self, index):\n",
    "        quest_and_answer = self.conversation.iloc[index]\n",
    "        quest_indexes = [quest_tokenizer.W2I[token] for token in quest_and_answer[\"question\"].split()]\n",
    "        quest_indexes.append(self.end_token)\n",
    "        ans_indexes = [ans_tokenizer.W2I[token] for token in quest_and_answer[\"answer\"].split()]\n",
    "        ans_indexes.append(self.end_token)\n",
    "        return torch.tensor(quest_indexes), torch.tensor(ans_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33ba2336",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet, testSet = train_test_split(df, test_size=0.20)\n",
    "\n",
    "validSet, testSet = train_test_split(testSet, test_size=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38f0eb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "CustomTrainSet = OwnDataset(trainSet, quest_tokenizer, ans_tokenizer)\n",
    "CustomTestSet = OwnDataset(testSet, quest_tokenizer, ans_tokenizer)\n",
    "CustomValidSet = OwnDataset(validSet, quest_tokenizer, ans_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5a98052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in training set: 104\n",
      "Number of samples in test set: 13\n",
      "Number of samples in validation set: 13\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of samples in training set: {len(CustomTrainSet)}\")\n",
    "print(f\"Number of samples in test set: {len(CustomTestSet)}\")\n",
    "print(f\"Number of samples in validation set: {len(CustomValidSet)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d31a3617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([167, 146,  78, 307, 220,   7,   1]),\n",
       " tensor([118, 298, 156, 116,  94,   1]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing one sample\n",
    "CustomTestSet[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef33fde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating mini batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65f6e433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(mini_batch):\n",
    "    padding_value=0\n",
    "    mini_batch = sorted(mini_batch, key=lambda pair: len(pair[0]), reverse=True)\n",
    "    question_tensor_list, answer_tensor_list = zip(*mini_batch)\n",
    "    max_len = len(question_tensor_list[0])\n",
    "    padded_question_tensor = pad_sequence(question_tensor_list, batch_first=True, padding_value=padding_value)\n",
    "    padded_answer_tensor = pad_sequence(answer_tensor_list, batch_first=True, padding_value=padding_value)\n",
    "    return padded_question_tensor, padded_answer_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47d94754",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in trainDataloader: 13\n",
      "\n",
      "Sample from batch 0:\n",
      "Questions:\n",
      "tensor([ 29, 343, 285, 183, 181,  19,  77, 206, 289, 132, 181, 102, 224, 238,\n",
      "        260, 282, 256,  27, 163,   1])\n",
      "Answers:\n",
      "tensor([104,   1, 281, 200,  45, 276,  26, 227,   1,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0])\n",
      "\n",
      "Sample from batch 1:\n",
      "Questions:\n",
      "tensor([188, 167, 225,  78, 311, 224,  28, 345, 106,  83,  79,   1])\n",
      "Answers:\n",
      "tensor([104, 243, 229, 174, 225,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0])\n",
      "\n",
      "Sample from batch 2:\n",
      "Questions:\n",
      "tensor([188,  23, 332, 280, 181, 253,  90,  12,  29, 329,  40,  78, 274, 263,\n",
      "         28, 236,   1])\n",
      "Answers:\n",
      "tensor([233, 256, 191, 197, 202, 313,  53,   1,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0])\n",
      "\n",
      "Sample from batch 3:\n",
      "Questions:\n",
      "tensor([ 29, 177,  78, 256,  27, 345, 106,  83,  79, 285, 224, 120,  62, 345,\n",
      "          1])\n",
      "Answers:\n",
      "tensor([104,  35, 204,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0])\n",
      "\n",
      "Sample from batch 4:\n",
      "Questions:\n",
      "tensor([326,  83,  79, 318, 224,  67, 172, 282,  28, 330,  22, 339, 132,  15,\n",
      "         29, 174, 341, 109, 276, 210, 351, 276,   1])\n",
      "Answers:\n",
      "tensor([ 84,  10,  26, 320, 319,  73,   3, 222,   1,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0])\n",
      "\n",
      "Sample from batch 5:\n",
      "Questions:\n",
      "tensor([327,  83,  79, 285, 154, 181, 113, 272, 210, 287, 210,  32, 111, 123,\n",
      "        285, 258,  29, 319, 247,  86, 284,   1])\n",
      "Answers:\n",
      "tensor([ 57, 229, 174, 225, 143,  26, 340,   1,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0])\n",
      "\n",
      "Sample from batch 6:\n",
      "Questions:\n",
      "tensor([203, 176, 293, 251, 140, 342, 282, 325, 224, 321, 262, 210, 338, 129,\n",
      "        222,   1])\n",
      "Answers:\n",
      "tensor([290, 128, 116,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0])\n",
      "\n",
      "Sample from batch 7:\n",
      "Questions:\n",
      "tensor([203, 318, 248, 224, 177, 210, 224, 226, 161, 210, 298, 131, 211,  78,\n",
      "        160, 305,  17,  58, 263, 286, 210, 171,  26,   1])\n",
      "Answers:\n",
      "tensor([167, 215, 218,  93,  34, 289,   1,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0])\n",
      "\n",
      "Sample from batch 8:\n",
      "Questions:\n",
      "tensor([ 29,  83, 247,  86, 285,  29, 139, 247, 320, 153,  78,  29, 101, 173,\n",
      "        198,  78,  69, 210,  98, 336,  83, 298,   1])\n",
      "Answers:\n",
      "tensor([ 60, 193, 185, 243, 221,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0])\n",
      "\n",
      "Sample from batch 9:\n",
      "Questions:\n",
      "tensor([326,  83,  79, 318, 224,  67, 172, 282,  28, 330,  22, 339, 132,  15,\n",
      "         29, 174, 341, 109, 276, 210, 351, 276,   1])\n",
      "Answers:\n",
      "tensor([ 84,  10,  26, 320, 319,  73,   3, 222,   1,   0,   0,   0,   0,   0,\n",
      "          0])\n",
      "Number of batches in valDataloader: 2\n",
      "\n",
      "Sample from batch 0:\n",
      "Questions:\n",
      "tensor([131, 124,  94, 166, 208,   0,  61, 155, 165,  13, 118, 181, 191,  29,\n",
      "        274, 190, 236,   1])\n",
      "Answers:\n",
      "tensor([249, 181,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0])\n",
      "\n",
      "Sample from batch 1:\n",
      "Questions:\n",
      "tensor([188,  23, 332, 280, 181, 218, 184, 224, 190, 278,  78, 310, 263,   1])\n",
      "Answers:\n",
      "tensor([ 60, 104, 243, 221,   1,   0,   0,   0,   0,   0])\n",
      "Number of batches in testDataloader: 2\n",
      "\n",
      "Sample from batch 0:\n",
      "Questions:\n",
      "tensor([ 29, 343, 285, 183, 181, 295, 298, 232, 158,   6, 210, 264, 271,   4,\n",
      "         12, 292,  35, 168,  78,  29, 117,  46,   1])\n",
      "Answers:\n",
      "tensor([  3,  35,  91,  84,  67,  26,  77, 125, 298, 334, 194, 129,   1])\n",
      "\n",
      "Sample from batch 1:\n",
      "Questions:\n",
      "tensor([ 29, 275, 345, 106,  83, 133, 307, 285, 224, 346, 345,   4, 187, 298,\n",
      "         93, 224, 192, 117, 141,   1])\n",
      "Answers:\n",
      "tensor([ 84, 305, 193, 214,  37,   1,   0])\n"
     ]
    }
   ],
   "source": [
    "trainDataloader = DataLoader(CustomTrainSet, batch_size=8, shuffle=True, collate_fn=padding)\n",
    "print(f\"Number of batches in trainDataloader: {len(trainDataloader)}\")\n",
    "for i, batch in enumerate(trainDataloader):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(f\"\\nSample from batch {i}:\")\n",
    "    print(f\"Questions:\\n{batch[0][0]}\")\n",
    "    print(f\"Answers:\\n{batch[1][0]}\")\n",
    "\n",
    "valDataloader = DataLoader(CustomTestSet, batch_size=8, shuffle=True, collate_fn=padding)\n",
    "print(f\"Number of batches in valDataloader: {len(valDataloader)}\")\n",
    "for i, batch in enumerate(valDataloader):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(f\"\\nSample from batch {i}:\")\n",
    "    print(f\"Questions:\\n{batch[0][0]}\")\n",
    "    print(f\"Answers:\\n{batch[1][0]}\")\n",
    "\n",
    "testDataloader = DataLoader(CustomValidSet, batch_size=8, shuffle=True, collate_fn=padding)\n",
    "print(f\"Number of batches in testDataloader: {len(testDataloader)}\")\n",
    "for i, batch in enumerate(testDataloader):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(f\"\\nSample from batch {i}:\")\n",
    "    print(f\"Questions:\\n{batch[0][0]}\")\n",
    "    print(f\"Answers:\\n{batch[1][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7a036e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff09a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466ffde4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
